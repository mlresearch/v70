---
title: Neural Optimizer Search with Reinforcement Learning
booktitle: Proceedings of the 34th International Conference on Machine Learning
year: '2017'
volume: '70'
series: Proceedings of Machine Learning Research
address: 
month: 0
publisher: PMLR
pdf: http://proceedings.mlr.press/v70/bello17a/bello17a.pdf
url: http://proceedings.mlr.press/v70/bello17a.html
abstract: We present an approach to automate the process of discovering optimization 
  methods, with a focus on deep learning architectures. We train a Recurrent Neural
  Network controller to generate a string in a domain specific language that describes
  a mathematical update equation based on a list of primitive functions, such as the
  gradient, running average of the gradient, etc. The controller is trained with Reinforcement 
  Learning to maximize the performance of a model after a few epochs. On CIFAR-10, 
  our method discovers several update rules that are better than many commonly used 
  optimizers, such as Adam, RMSProp, or SGD with and without Momentum on a ConvNet 
  model. We introduce two new optimizers, named PowerSign and AddSign, which we show 
  transfer well and improve training on a variety of different tasks and architectures, 
  including ImageNet classification and Google's neural machine translation system.
layout: inproceedings
id: bello17a
tex_title: Neural Optimizer Search with Reinforcement Learning
bibtex_author: Irwan Bello and Barret Zoph and Vijay Vasudevan and Quoc V. Le
firstpage: 459
lastpage: 468
page: 459-468
order: 459
cycles: false
editor:
- given: Doina
  family: Precup
- given: Yee Whye
  family: Teh
author:
- given: Irwan
  family: Bello
- given: Barret
  family: Zoph
- given: Vijay
  family: Vasudevan
- given: Quoc V.
  family: Le
date: 2017-07-17
container-title: Proceedings of the 34th International Conference on Machine Learning
genre: inproceedings
issued:
  date-parts:
  - 2017
  - 7
  - 17
extras: []
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
